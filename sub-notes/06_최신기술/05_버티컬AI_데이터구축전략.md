# 버티컬 AI 데이터 구축 전략

## 1. 정의 및 배경

### 1.1 정의
**버티컬 AI(Vertical AI)**는 특정 도메인(의료, 법률, 금융 등)에 특화된 AI 모델로, 범용 LLM 대비 **전문성, 정확성, 컴플라이언스**를 강화한 AI다. 도메인 특화 데이터로 파인튜닝하거나 RAG를 결합하여 구축한다.

### 1.2 출제 배경
- **정책**: NIA 2025 초거대 AI 생태계 구축 + 버티컬 AI 데이터 수요조사
- **문제**: 범용 LLM(GPT-4, Claude)의 도메인 한계
  - 의료: 환각(Hallucination)으로 잘못된 진단 제시
  - 법률: 최신 판례 부재 (학습 컷오프 시점)
  - 금융: 규제 컴플라이언스 미준수
- **근본 원인**: 범용 데이터 학습 → 전문 지식 부족 + 도메인 용어 오해

### 1.3 필요성
1. **정확성**: 의료 AI 진단 정확도 70% → 95% (전문 데이터 학습 시)
2. **컴플라이언스**: HIPAA, GDPR 등 규제 준수
3. **비용 효율**: 범용 LLM API 호출 비용 vs 자체 모델 운영
4. **데이터 주권**: 민감 데이터 외부 유출 방지

---

## 2. 범용 LLM vs 버티컬 AI

### 2.1 범용 LLM의 한계

```
[범용 LLM의 도메인 오류 사례]

사례 1: 의료 진단
┌────────────────────────────────────────────┐
│ 질문: "고혈압 환자가 아스피린을 복용해도 되나요?" │
├────────────────────────────────────────────┤
│ GPT-4 답변:                                 │
│ "일반적으로 고혈압 환자는 아스피린을 복용할 수 │
│  있습니다. 단, 의사와 상담하세요."            │
├────────────────────────────────────────────┤
│ 문제점:                                     │
│ ✗ 출혈 위험 환자(위궤양, 혈우병) 고려 없음   │
│ ✗ 약물 상호작용 (와파린 등) 확인 필요        │
│ ✗ 용량, 복용 시간 등 구체적 정보 부재        │
└────────────────────────────────────────────┘

사례 2: 법률 자문
┌────────────────────────────────────────────┐
│ 질문: "임대차계약 갱신 시 임대료 인상 한도는?" │
├────────────────────────────────────────────┤
│ GPT-4 답변:                                 │
│ "일반적으로 5% 이내로 인상 가능합니다."      │
├────────────────────────────────────────────┤
│ 문제점:                                     │
│ ✗ 2020년 개정 주택임대차보호법 미반영       │
│ ✗ 실제: 5% → 계약갱신청구권 도입 이후 변경  │
│ ✗ 2024년 판례 부재 (학습 컷오프: 2023.01)   │
└────────────────────────────────────────────┘

사례 3: 금융 규제
┌────────────────────────────────────────────┐
│ 질문: "가상자산 과세 기준은?"                │
├────────────────────────────────────────────┤
│ GPT-4 답변:                                 │
│ "가상자산 소득은 기타소득으로 분류되며..."   │
├────────────────────────────────────────────┤
│ 문제점:                                     │
│ ✗ 2025년 시행 예정 과세 유예 미반영         │
│ ✗ 국가별 규제 차이 (한국 vs 미국) 혼동      │
│ ✗ 최신 금융당국 가이드라인 부재             │
└────────────────────────────────────────────┘
```

### 2.2 버티컬 AI vs 범용 LLM 비교

| 항목 | 범용 LLM (GPT-4) | 버티컬 AI (도메인 특화) |
|------|------------------|------------------------|
| **데이터** | 웹 크롤링 (일반) | 전문 데이터셋 + 최신 정보 |
| **정확성** | 70~80% | 90~98% |
| **환각률** | 15~20% | 3~5% |
| **용어 이해** | 표면적 | 깊이 있는 컨텍스트 |
| **규제 준수** | 어려움 | 설계 단계부터 반영 |
| **비용** | API 호출 (종량제) | 자체 운영 (고정비) |
| **데이터 보안** | 외부 전송 | 온프레미스 가능 |
| **커스터마이징** | 제한적 (프롬프트만) | 완전 제어 |

---

## 3. 버티컬 AI 데이터 구축 전략

### 3.1 데이터 수집 방법론

#### (1) 데이터 소스 분류

```
[도메인별 데이터 소스]

┌─────────────────────────────────────────────────────────┐
│ 의료 (Healthcare)                                        │
├─────────────────────────────────────────────────────────┤
│ • 진료 기록 (EMR/EHR)                                    │
│ • 의학 논문 (PubMed, 대한의학회)                         │
│ • 임상 가이드라인 (NCCN, UpToDate)                       │
│ • 의약품 설명서 (식약처 DB)                              │
│ • 의료영상 판독 레포트                                   │
│ • 환자-의사 대화 기록 (익명화)                           │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│ 법률 (Legal)                                             │
├─────────────────────────────────────────────────────────┤
│ • 판례 (대법원 종합법률정보)                             │
│ • 법령 (국가법령정보센터)                                │
│ • 법률 자문 사례                                         │
│ • 계약서 템플릿                                          │
│ • 법학 논문 (Law Review)                                │
│ • 변호사-의뢰인 Q&A (익명화)                             │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│ 금융 (Finance)                                           │
├─────────────────────────────────────────────────────────┤
│ • 금융 규제 (금융감독원 가이드)                          │
│ • 투자 리포트 (증권사 리서치)                            │
│ • 경제 지표 (한국은행, Bloomberg)                        │
│ • 금융 상품 설명서                                       │
│ • 고객 상담 기록                                         │
│ • 신용평가 데이터                                        │
└─────────────────────────────────────────────────────────┘
```

#### (2) 데이터 수집 파이프라인

```python
class VerticalAIDataCollector:
    """버티컬 AI 데이터 수집 엔진"""

    def __init__(self, domain):
        self.domain = domain
        self.data_sources = self.get_domain_sources(domain)

    def collect_domain_data(self):
        """도메인 특화 데이터 수집"""
        collected_data = []

        for source in self.data_sources:
            if source['type'] == 'api':
                data = self.collect_from_api(source)
            elif source['type'] == 'web_scraping':
                data = self.collect_from_web(source)
            elif source['type'] == 'database':
                data = self.collect_from_db(source)
            elif source['type'] == 'manual':
                data = self.collect_manual(source)

            # 데이터 검증
            validated_data = self.validate_data(data, source)

            # 메타데이터 추가
            enriched_data = self.add_metadata(validated_data, source)

            collected_data.extend(enriched_data)

        return collected_data

    def collect_from_api(self, source):
        """API를 통한 데이터 수집 (예: PubMed)"""
        if self.domain == 'medical':
            # PubMed API 호출
            papers = self.fetch_pubmed_papers(
                query=source['query'],
                max_results=source['max_results'],
                date_range='2020-2025'
            )

            return papers

    def collect_from_web(self, source):
        """웹 스크래핑 (예: 판례 크롤링)"""
        if self.domain == 'legal':
            # 대법원 판례 크롤링
            cases = []
            for year in range(2020, 2025):
                url = f"{source['base_url']}/search?year={year}"
                html = requests.get(url).text
                soup = BeautifulSoup(html, 'html.parser')

                # 판례 추출
                case_elements = soup.find_all('div', class_='case-item')
                for elem in case_elements:
                    case = {
                        'title': elem.find('h3').text,
                        'court': elem.find('span', class_='court').text,
                        'date': elem.find('span', class_='date').text,
                        'summary': elem.find('p', class_='summary').text,
                        'full_text': self.fetch_case_detail(elem['data-id'])
                    }
                    cases.append(case)

            return cases

    def validate_data(self, data, source):
        """데이터 품질 검증"""
        validated = []

        for item in data:
            # 1. 완전성 (Completeness) 검사
            required_fields = source['required_fields']
            if not all(field in item for field in required_fields):
                continue

            # 2. 정확성 (Accuracy) 검사
            if self.domain == 'medical':
                # 의학 용어 검증
                if not self.validate_medical_terms(item['text']):
                    continue

            # 3. 일관성 (Consistency) 검사
            if 'date' in item:
                if not self.validate_date_format(item['date']):
                    continue

            # 4. 중복 제거 (Deduplication)
            if self.is_duplicate(item, validated):
                continue

            validated.append(item)

        return validated

    def add_metadata(self, data, source):
        """메타데이터 추가 (데이터 계보 추적)"""
        enriched = []

        for item in data:
            item['metadata'] = {
                'source_name': source['name'],
                'collection_date': datetime.now().isoformat(),
                'domain': self.domain,
                'quality_score': self.calculate_quality_score(item),
                'license': source.get('license', 'proprietary'),
                'version': '1.0'
            }

            # 도메인별 메타데이터 추가
            if self.domain == 'medical':
                item['metadata']['medical_specialty'] = self.classify_specialty(item)
                item['metadata']['evidence_level'] = self.assess_evidence(item)

            elif self.domain == 'legal':
                item['metadata']['law_category'] = self.classify_law_category(item)
                item['metadata']['precedent_level'] = self.assess_precedent(item)

            enriched.append(item)

        return enriched
```

### 3.2 데이터 전처리 및 정제

#### (1) 의료 데이터 익명화 (De-identification)

```python
class MedicalDataDeidentifier:
    """의료 데이터 개인정보 제거 (HIPAA 준수)"""

    def deidentify_emr(self, emr_text):
        """전자의무기록(EMR) 익명화"""
        # HIPAA Safe Harbor 기준 18가지 식별자 제거

        # 1. 이름
        emr_text = self.remove_names(emr_text)

        # 2. 날짜 (연도 제외)
        emr_text = self.mask_dates(emr_text)

        # 3. 전화번호, 팩스번호
        emr_text = re.sub(r'\d{3}-\d{4}-\d{4}', '[PHONE]', emr_text)

        # 4. 주민등록번호, 의료보험번호
        emr_text = re.sub(r'\d{6}-\d{7}', '[SSN]', emr_text)

        # 5. 주소 (시/도 수준만 유지)
        emr_text = self.mask_address(emr_text)

        # 6. IP 주소, MAC 주소
        emr_text = re.sub(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}', '[IP]', emr_text)

        # 7. 의료기록번호 (MRN)
        emr_text = re.sub(r'MRN:\s*\d+', 'MRN: [REDACTED]', emr_text)

        return emr_text

    def remove_names(self, text):
        """NER 모델을 이용한 이름 제거"""
        # spaCy NER 모델 사용
        doc = self.nlp(text)

        for ent in doc.ents:
            if ent.label_ == 'PERSON':
                text = text.replace(ent.text, '[NAME]')

        return text

    def mask_dates(self, text):
        """날짜 마스킹 (연도는 유지)"""
        # 예: 2024년 3월 15일 → 2024년 [DATE]
        date_patterns = [
            r'(\d{4})년\s*\d{1,2}월\s*\d{1,2}일',
            r'(\d{4})-\d{2}-\d{2}',
            r'(\d{4})/\d{2}/\d{2}'
        ]

        for pattern in date_patterns:
            text = re.sub(pattern, r'\1년 [DATE]', text)

        return text
```

#### (2) 합성 데이터 생성 (Synthetic Data)

```python
class SyntheticDataGenerator:
    """합성 데이터 생성 (실제 데이터 부족 시)"""

    def generate_synthetic_medical_cases(self, num_samples, template):
        """의료 진단 케이스 합성 생성"""
        synthetic_cases = []

        for _ in range(num_samples):
            case = {
                'chief_complaint': self.sample_complaint(),
                'vital_signs': self.generate_vitals(),
                'symptoms': self.sample_symptoms(),
                'diagnosis': self.generate_diagnosis(),
                'treatment': self.generate_treatment()
            }

            # LLM을 이용한 자연어 변환
            case_text = self.llm_generate_case_narrative(case, template)

            # 의학적 타당성 검증
            if self.validate_medical_plausibility(case):
                synthetic_cases.append(case_text)

        return synthetic_cases

    def generate_vitals(self):
        """생체 신호 생성 (정상 범위 + 변동)"""
        return {
            'blood_pressure_systolic': np.random.normal(120, 15),
            'blood_pressure_diastolic': np.random.normal(80, 10),
            'heart_rate': np.random.normal(75, 10),
            'temperature': np.random.normal(36.5, 0.5),
            'respiratory_rate': np.random.normal(16, 2)
        }

    def llm_generate_case_narrative(self, case, template):
        """LLM으로 자연스러운 진료 기록 생성"""
        prompt = f"""
        다음 정보를 바탕으로 실제 의사가 작성한 것 같은 진료 기록을 생성하세요.

        주 호소: {case['chief_complaint']}
        생체 신호: {case['vital_signs']}
        증상: {case['symptoms']}
        진단: {case['diagnosis']}
        치료: {case['treatment']}

        템플릿: {template}
        """

        narrative = self.llm.generate(prompt)
        return narrative
```

### 3.3 데이터 품질 관리 (DQM)

```python
class DomainDataQualityManager:
    """도메인 특화 데이터 품질 관리"""

    def assess_data_quality(self, dataset, domain):
        """6가지 품질 차원 평가"""
        quality_report = {
            'completeness': self.check_completeness(dataset),
            'accuracy': self.check_accuracy(dataset, domain),
            'consistency': self.check_consistency(dataset),
            'timeliness': self.check_timeliness(dataset),
            'uniqueness': self.check_uniqueness(dataset),
            'validity': self.check_validity(dataset, domain)
        }

        # 종합 점수 계산
        overall_score = sum(quality_report.values()) / len(quality_report)

        return {
            'overall_score': overall_score,
            'details': quality_report,
            'recommendations': self.generate_recommendations(quality_report)
        }

    def check_accuracy(self, dataset, domain):
        """정확성 검증 (도메인 전문가 검토)"""
        if domain == 'medical':
            return self.check_medical_accuracy(dataset)
        elif domain == 'legal':
            return self.check_legal_accuracy(dataset)

    def check_medical_accuracy(self, dataset):
        """의료 데이터 정확성 검증"""
        # 1. 의학 용어 검증
        medical_terms = self.load_medical_terminology_db()
        term_accuracy = 0

        for item in dataset:
            terms_in_text = self.extract_medical_terms(item['text'])
            valid_terms = [t for t in terms_in_text if t in medical_terms]
            term_accuracy += len(valid_terms) / len(terms_in_text)

        term_accuracy /= len(dataset)

        # 2. 약물-질병 관계 검증
        drug_disease_valid = self.validate_drug_disease_pairs(dataset)

        # 3. 진단-치료 일관성
        diagnosis_treatment_valid = self.validate_diagnosis_treatment(dataset)

        # 종합 정확성 점수
        accuracy_score = (term_accuracy + drug_disease_valid + diagnosis_treatment_valid) / 3

        return accuracy_score

    def check_timeliness(self, dataset):
        """최신성 검증"""
        current_year = datetime.now().year
        timeliness_scores = []

        for item in dataset:
            if 'metadata' in item and 'date' in item['metadata']:
                data_year = datetime.fromisoformat(item['metadata']['date']).year
                age = current_year - data_year

                # 데이터 나이에 따른 점수 (최근일수록 높음)
                if age == 0:
                    score = 1.0
                elif age <= 2:
                    score = 0.9
                elif age <= 5:
                    score = 0.7
                else:
                    score = 0.3

                timeliness_scores.append(score)

        return sum(timeliness_scores) / len(timeliness_scores)
```

---

## 4. 파인튜닝 vs RAG 전략

### 4.1 접근 방식 비교

```
[파인튜닝 vs RAG 아키텍처]

┌─────────────────────────────────────────────────────────┐
│ Fine-tuning (파인튜닝)                                   │
├─────────────────────────────────────────────────────────┤
│                                                          │
│  ┌──────────┐    도메인 데이터     ┌──────────┐         │
│  │ Base LLM │ ─────────────────→  │ Vertical  │         │
│  │(Llama 3) │   재학습 (Gradient) │  AI Model │         │
│  └──────────┘                     └──────────┘         │
│                                         ↓               │
│                                   모델 가중치 변경       │
│                                                          │
│  장점:                                                   │
│  ✓ 추론 속도 빠름 (외부 검색 불필요)                     │
│  ✓ 도메인 지식이 모델에 내재화                           │
│  ✓ 오프라인 동작 가능                                    │
│                                                          │
│  단점:                                                   │
│  ✗ 학습 비용 높음 (GPU, 시간)                            │
│  ✗ 최신 정보 반영 어려움 (재학습 필요)                   │
│  ✗ Catastrophic Forgetting (기존 지식 손실)             │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│ RAG (Retrieval-Augmented Generation)                    │
├─────────────────────────────────────────────────────────┤
│                                                          │
│  사용자 질문 → 임베딩 → 벡터 검색 → 컨텍스트 주입       │
│                                                          │
│  ┌────────┐     ┌──────────┐     ┌────────┐             │
│  │ Query  │ ──→ │ Vector DB│ ──→ │ LLM +  │ → 답변     │
│  └────────┘     │ (HNSW)   │     │Context │             │
│                 └──────────┘     └────────┘             │
│                      ↑                                   │
│              도메인 문서 (실시간 업데이트)                │
│                                                          │
│  장점:                                                   │
│  ✓ 최신 정보 즉시 반영 (문서만 추가)                     │
│  ✓ 학습 비용 없음                                        │
│  ✓ 출처 추적 가능 (인용)                                 │
│                                                          │
│  단점:                                                   │
│  ✗ 추론 속도 느림 (검색 오버헤드)                        │
│  ✗ 검색 품질에 성능 의존                                 │
│  ✗ 컨텍스트 길이 제한 (4K~128K 토큰)                    │
└─────────────────────────────────────────────────────────┘
```

### 4.2 선택 기준

| 기준 | 파인튜닝 우선 | RAG 우선 |
|------|---------------|----------|
| **데이터 특성** | 정적 (연간 변화 < 10%) | 동적 (월간 업데이트) |
| **데이터 크기** | 대규모 (100GB+) | 소규모 (1~10GB) |
| **정확성 요구** | 초고 (99%+) | 고 (95%+) |
| **응답 속도** | 실시간 (< 100ms) | 준실시간 (< 1s) |
| **비용** | 초기 투자 가능 | 운영비 중심 |
| **유지보수** | 분기별 재학습 가능 | 실시간 업데이트 필요 |

**예시**:
- **의료 진단 AI**: 파인튜닝 (의학 지식은 안정적, 고정확성 필요)
- **법률 자문 AI**: RAG (판례는 매월 추가, 출처 인용 필수)
- **금융 규제 AI**: 하이브리드 (기본 지식은 파인튜닝 + 최신 규제는 RAG)

### 4.3 하이브리드 접근 (Fine-tuning + RAG)

```python
class HybridVerticalAI:
    """파인튜닝 + RAG 하이브리드 모델"""

    def __init__(self, base_model, domain):
        # 1. 도메인 특화 파인튜닝 모델
        self.finetuned_model = self.load_finetuned_model(
            base_model, domain
        )

        # 2. RAG 검색 엔진
        self.vector_db = self.initialize_vector_db(domain)
        self.retriever = self.initialize_retriever()

    def generate_response(self, query, use_rag=True):
        """하이브리드 추론"""
        if use_rag:
            # 1. RAG 검색으로 최신 정보 획득
            retrieved_docs = self.retriever.retrieve(
                query, top_k=5
            )

            # 2. 파인튜닝 모델에 컨텍스트 주입
            context = self.format_retrieved_context(retrieved_docs)
            prompt = f"""
            다음 참고 문서를 바탕으로 질문에 답변하세요.

            참고 문서:
            {context}

            질문: {query}

            답변:
            """

            response = self.finetuned_model.generate(prompt)

            return {
                'answer': response,
                'sources': [doc['metadata']['source'] for doc in retrieved_docs],
                'confidence': self.calculate_confidence(response, retrieved_docs)
            }
        else:
            # RAG 없이 파인튜닝 모델만 사용 (빠른 추론)
            response = self.finetuned_model.generate(query)
            return {'answer': response}

    def calculate_confidence(self, response, retrieved_docs):
        """답변 신뢰도 계산"""
        # 1. 검색된 문서와 답변의 유사도
        answer_embedding = self.embed_text(response)
        doc_embeddings = [self.embed_text(doc['content']) for doc in retrieved_docs]

        similarities = [
            cosine_similarity(answer_embedding, doc_emb)
            for doc_emb in doc_embeddings
        ]

        # 2. 평균 유사도가 높을수록 신뢰도 높음
        confidence = sum(similarities) / len(similarities)

        return confidence
```

---

## 5. 파인튜닝 상세 구현

### 5.1 의료 AI 파인튜닝 예시

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments
from datasets import load_dataset
import torch

class MedicalAIFineTuner:
    """의료 AI 파인튜닝 파이프라인"""

    def __init__(self, base_model='meta-llama/Llama-3-8B'):
        self.base_model_name = base_model
        self.model = AutoModelForCausalLM.from_pretrained(base_model)
        self.tokenizer = AutoTokenizer.from_pretrained(base_model)

    def prepare_medical_dataset(self, data_path):
        """의료 데이터셋 준비"""
        # 1. 원시 데이터 로드
        raw_data = load_dataset('json', data_files=data_path)

        # 2. 지시 튜닝 포맷으로 변환
        def format_medical_instruction(example):
            """의료 Q&A를 지시 튜닝 포맷으로 변환"""
            prompt = f"""<|im_start|>system
당신은 대한민국의 전문 의사입니다. 환자의 질문에 정확하고 안전한 의학 정보를 제공하세요.
<|im_end|>
<|im_start|>user
{example['question']}
<|im_end|>
<|im_start|>assistant
{example['answer']}
<|im_end|>"""

            return {'text': prompt}

        formatted_data = raw_data.map(format_medical_instruction)

        # 3. 토큰화
        def tokenize(example):
            return self.tokenizer(
                example['text'],
                truncation=True,
                max_length=2048,
                padding='max_length'
            )

        tokenized_data = formatted_data.map(tokenize, batched=True)

        return tokenized_data

    def finetune(self, train_dataset, eval_dataset):
        """LoRA 기반 파인튜닝 (메모리 효율적)"""
        from peft import LoraConfig, get_peft_model, TaskType

        # LoRA 설정
        lora_config = LoraConfig(
            task_type=TaskType.CAUSAL_LM,
            r=16,  # LoRA rank
            lora_alpha=32,
            lora_dropout=0.05,
            target_modules=["q_proj", "v_proj", "k_proj", "o_proj"]
        )

        # LoRA 적용
        model = get_peft_model(self.model, lora_config)

        # 학습 설정
        training_args = TrainingArguments(
            output_dir='./medical-llama-lora',
            num_train_epochs=3,
            per_device_train_batch_size=4,
            gradient_accumulation_steps=8,
            learning_rate=2e-5,
            fp16=True,  # Mixed Precision Training
            logging_steps=10,
            evaluation_strategy='steps',
            eval_steps=500,
            save_steps=500,
            warmup_steps=100,
            # 의료 데이터 보안
            push_to_hub=False,  # 외부 유출 방지
            report_to='none'
        )

        # Trainer 초기화
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=eval_dataset,
            # 데이터 콜레이터
            data_collator=self.get_data_collator()
        )

        # 학습 실행
        trainer.train()

        return model

    def evaluate_medical_accuracy(self, model, test_dataset):
        """의료 AI 정확성 평가"""
        results = {
            'medical_accuracy': 0,
            'safety_score': 0,
            'hallucination_rate': 0
        }

        for example in test_dataset:
            question = example['question']
            ground_truth = example['answer']

            # 모델 답변 생성
            generated_answer = self.generate(model, question)

            # 1. 의학적 정확성 (전문가 평가 대체: 키워드 매칭)
            key_concepts = self.extract_medical_concepts(ground_truth)
            accuracy = self.calculate_concept_overlap(
                generated_answer, key_concepts
            )
            results['medical_accuracy'] += accuracy

            # 2. 안전성 점수 (위험한 조언 탐지)
            safety = self.check_medical_safety(generated_answer)
            results['safety_score'] += safety

            # 3. 환각 탐지 (근거 없는 주장)
            hallucination = self.detect_hallucination(
                generated_answer, example['context']
            )
            results['hallucination_rate'] += hallucination

        # 평균 계산
        n = len(test_dataset)
        results = {k: v / n for k, v in results.items()}

        return results

    def check_medical_safety(self, answer):
        """의료 안전성 검사"""
        # 위험 키워드 탐지
        dangerous_phrases = [
            '진단할 수 있습니다',  # 자가 진단 유도
            '약을 중단하세요',      # 임의 투약 중단
            '병원 방문 불필요',     # 의료 회피 유도
            '확실히 ~입니다'        # 과신
        ]

        safety_violations = sum(
            1 for phrase in dangerous_phrases
            if phrase in answer
        )

        # 안전 권고 포함 여부
        safe_phrases = [
            '의사와 상담',
            '전문가 진료',
            '정확한 진단을 위해'
        ]

        safe_recommendations = sum(
            1 for phrase in safe_phrases
            if phrase in answer
        )

        # 점수 계산 (0~1, 높을수록 안전)
        safety_score = (safe_recommendations - safety_violations) / len(safe_phrases)
        safety_score = max(0, min(1, safety_score))

        return safety_score
```

---

## 6. 실무 사례 및 성능

### 6.1 도메인별 구축 사례

#### 사례 1: A병원 의료 AI (2024)

**Before (범용 LLM)**:
```
모델: GPT-4 API
정확성: 73%
환각률: 18%
월 API 비용: $15,000
컴플라이언스: HIPAA 위반 우려 (데이터 외부 전송)
```

**After (버티컬 AI - 파인튜닝)**:
```
모델: Llama 3 8B + 10만 건 진료기록 파인튜닝
정확성: 94%
환각률: 4%
월 운영 비용: $3,000 (자체 GPU 서버)
컴플라이언스: HIPAA 준수 (온프레미스)

ROI:
- 비용 절감: $12,000/월 (80%)
- 의사 업무 시간 절감: 30% (예진 자동화)
- 오진율 감소: 15% → 3%
```

#### 사례 2: B로펌 법률 AI (2024)

**Approach: RAG 기반**
```
모델: Claude 3 Sonnet + RAG
데이터: 대법원 판례 50만 건 + 법령 10만 건
벡터 DB: Qdrant (HNSW)
임베딩: bge-m3-korean

성능:
- 판례 검색 정확도: Recall@10 = 92%
- 답변 정확도: 89% (변호사 검증)
- 평균 응답 시간: 2.3초
- 출처 인용: 100% (모든 답변에 판례 번호 제공)

효과:
- 법률 리서치 시간: 4시간 → 30분 (87% 단축)
- 주니어 변호사 생산성 300% 향상
```

#### 사례 3: C증권사 금융 AI (하이브리드)

**Approach: 파인튜닝 + RAG**
```
기본 모델: Mistral 7B + 금융 데이터 파인튜닝
RAG: 최신 공시, 뉴스 (매일 업데이트)

아키텍처:
1. 파인튜닝 모델: 금융 용어, 분석 패턴 학습
2. RAG: 최신 뉴스, 실시간 지표 제공

성능:
- 투자 리포트 생성 시간: 2일 → 2시간
- 정확성: 91% (애널리스트 검증)
- 규제 준수: 금융감독원 가이드 100% 반영

비용:
- 애널리스트 리포트 작성 비용 60% 절감
```

### 6.2 성능 벤치마크

```python
# 의료 AI 벤치마크 결과

benchmark_results = {
    "MedQA (USMLE)": {
        "GPT-4": 86.7,
        "Med-PaLM 2": 86.5,
        "Llama 3 70B (범용)": 74.2,
        "Llama 3 8B + Fine-tuning (우리 모델)": 82.3
    },
    "PubMedQA": {
        "GPT-4": 78.2,
        "Llama 3 8B + Fine-tuning": 84.1  # 도메인 특화 우위
    },
    "환각률 (Hallucination Rate)": {
        "GPT-4": 15.3,
        "Llama 3 8B + Fine-tuning": 4.2
    }
}

# 법률 AI 벤치마크

legal_benchmark = {
    "판례 검색 (Recall@10)": {
        "키워드 검색": 45.2,
        "BM25": 62.3,
        "RAG (bge-m3)": 91.8
    },
    "법률 QA 정확도": {
        "GPT-4": 71.5,
        "Claude 3 Opus": 75.2,
        "Claude 3 + RAG (우리 모델)": 89.1
    }
}
```

---

## 7. 한계 및 개선 방향

### 7.1 현재 한계

1. **고품질 데이터 부족**: 전문가 레이블링 비용 (시간당 $100~$300)
2. **도메인 편향**: 특정 전문 분야에 과적합 (Overfitting)
3. **Catastrophic Forgetting**: 파인튜닝 시 기존 일반 지식 손실
4. **컴플라이언스 복잡도**: 규제 준수 검증 어려움 (HIPAA, GDPR)

### 7.2 개선 방향

1. **능동 학습 (Active Learning)**: 불확실한 케이스만 전문가 검토
2. **연합 학습 (Federated Learning)**: 병원 간 데이터 공유 없이 협업 학습
3. **지속 학습 (Continual Learning)**: 새 지식 추가 시 기존 지식 보존
4. **자동 컴플라이언스 검증**: 규제 룰을 코드로 자동 검사

---

## 8. 시사점

### 8.1 기술적 시사점
- **데이터 품질 > 모델 크기**: 작은 모델 + 고품질 데이터 > 큰 범용 모델
- **하이브리드 최적**: 파인튜닝(안정 지식) + RAG(최신 정보)
- **도메인 전문가 필수**: AI 엔지니어 + 의사/변호사 협업

### 8.2 정책적 시사점
1. **NIA 2025 사업**: 의료/법률/금융 등 7개 도메인 데이터 구축 예산 확대
2. **데이터 주권**: 공공 데이터 개방 + 민감 데이터 보호 균형
3. **인증 체계**: 버티컬 AI 성능 인증 기준 마련 필요

### 8.3 출제 예상 각도
- "버티컬 AI를 위한 데이터 구축 전략" (NIA 정책 연계)
- "의료 AI의 HIPAA 준수 방안"
- "파인튜닝 vs RAG 비교 및 선택 기준"
- "도메인 특화 LLM의 평가 지표"

---

## 참고문헌
- NIA, "2025 초거대 AI 데이터 수요조사"
- Google, "Med-PaLM 2 논문"
- Meta, "Llama 3 Technical Report"
- HIPAA, "De-identification Guidance"

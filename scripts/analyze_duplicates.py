#!/usr/bin/env python3
"""
129~137íšŒ ì¤‘ë³µ ë¬¸ì œ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
"""

import json
import os
from collections import defaultdict
import re

def clean_question_title(title):
    """ë¬¸ì œ ì œëª©ì—ì„œ ë²ˆí˜¸ ë“±ì„ ì œê±°í•˜ê³  í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ"""
    # ë§¨ ì•ì˜ ë²ˆí˜¸ ì œê±° (ì˜ˆ: "1. ", "ê°€. " ë“±)
    title = re.sub(r'^[\dê°€-í£]+\.\s*', '', title)
    # ë”°ì˜´í‘œ ì œê±°
    title = title.replace('"', '').replace("'", '').strip()
    return title

def extract_keywords_from_title(title):
    """ì œëª©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ê´„í˜¸ ì•ˆ ì˜ë¬¸ í¬í•¨)"""
    keywords = set()

    # ì˜ë¬¸ ì•½ì–´ ì¶”ì¶œ (ê´„í˜¸ ì•ˆ)
    acronyms = re.findall(r'\(([A-Z][A-Za-z0-9\s,/&]+)\)', title)
    keywords.update(acronyms)

    # í•œê¸€ í•µì‹¬ í‚¤ì›Œë“œ (3ê¸€ì ì´ìƒ)
    korean_words = re.findall(r'[ê°€-í£]{3,}', title)
    keywords.update(korean_words)

    return keywords

def main():
    # ëª¨ë“  íšŒì°¨ì˜ ë¬¸ì œ ìˆ˜ì§‘
    all_questions = []
    question_by_title = defaultdict(list)
    keyword_frequency = defaultdict(lambda: defaultdict(list))  # keyword -> {session: [questions]}

    exam_sessions = range(129, 138)

    for session in exam_sessions:
        file_path = f'/Users/jyk/projects/sub-note/data/exam_results/{session}íšŒ_ë¶„ì„ê²°ê³¼.json'
        if not os.path.exists(file_path):
            continue

        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # ê° êµì‹œë³„ ë¬¸ì œ ì²˜ë¦¬
        questions_data = data.get('questions', {})
        for session_name, questions in questions_data.items():
            for q in questions:
                title = q.get('ì œëª©', '').strip()
                number = q.get('ë²ˆí˜¸', '')

                if not title:
                    continue

                full_id = f"{session}íšŒ {session_name} {number}"
                cleaned_title = clean_question_title(title)

                all_questions.append({
                    'session': session,
                    'session_name': session_name,
                    'number': number,
                    'full_id': full_id,
                    'title': title,
                    'cleaned_title': cleaned_title
                })

                # ì™„ì „ ì¼ì¹˜ ì¤‘ë³µ ì²´í¬
                question_by_title[cleaned_title].append(full_id)

                # í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„ ì²´í¬
                keywords = extract_keywords_from_title(title)
                for kw in keywords:
                    keyword_frequency[kw][session].append({
                        'full_id': full_id,
                        'title': title
                    })

    print('=' * 100)
    print(f'ğŸ“Š 129~137íšŒ ì •ë³´ê´€ë¦¬ê¸°ìˆ ì‚¬ ì¤‘ë³µ ë¬¸ì œ ë¶„ì„')
    print('=' * 100)
    print(f'\nì´ ë¶„ì„ ë¬¸ì œ ìˆ˜: {len(all_questions)}ê°œ (9ê°œ íšŒì°¨ Ã— 31ë¬¸ì œ = 279ê°œ)\n')

    # 1. ì™„ì „ ì¤‘ë³µ ë¬¸ì œ
    exact_duplicates = {title: ids for title, ids in question_by_title.items() if len(ids) > 1}
    print(f'\nğŸ” 1. ì™„ì „ ì¤‘ë³µ ë¬¸ì œ (ì œëª©ì´ ë™ì¼í•œ ê²½ìš°): {len(exact_duplicates)}ê°œ')
    print('-' * 100)

    if exact_duplicates:
        for title, ids in sorted(exact_duplicates.items(), key=lambda x: len(x[1]), reverse=True):
            print(f'\nâ€¢ ì¶œì œ íšŸìˆ˜: {len(ids)}íšŒ')
            print(f'  ì œëª©: {title[:80]}...' if len(title) > 80 else f'  ì œëª©: {title}')
            print(f'  ì¶œì œ íšŒì°¨: {", ".join(ids)}')
    else:
        print('âœ… ì™„ì „íˆ ë™ì¼í•œ ì œëª©ì˜ ë¬¸ì œëŠ” ì—†ìŠµë‹ˆë‹¤.')

    # 2. í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ ë¬¸ì œ (2íšŒ ì´ìƒ ì¶œì œ)
    print(f'\n\nğŸ” 2. í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ ì£¼ì œ ë¶„ì„ (2íšŒ ì´ìƒ ì¶œì œëœ ì£¼ì œ)')
    print('-' * 100)

    # ì£¼ìš” í‚¤ì›Œë“œë§Œ í•„í„°ë§ (3íšŒ ì´ìƒ ì¶œì œëœ ê²ƒë§Œ)
    frequent_keywords = {kw: sessions for kw, sessions in keyword_frequency.items()
                        if len(sessions) >= 2 and len(kw) >= 3}

    # ì¶œì œ íšŸìˆ˜ ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_keywords = sorted(frequent_keywords.items(),
                            key=lambda x: sum(len(qs) for qs in x[1].values()),
                            reverse=True)

    print(f'\nì´ {len(sorted_keywords)}ê°œì˜ í‚¤ì›Œë“œê°€ 2íšŒ ì´ìƒ ì¶œì œë¨\n')

    # ìƒìœ„ 30ê°œë§Œ ì¶œë ¥
    for kw, sessions in sorted_keywords[:30]:
        total_count = sum(len(qs) for qs in sessions.values())
        session_list = sorted(sessions.keys())

        print(f'\nğŸ“Œ "{kw}" - ì´ {total_count}íšŒ ì¶œì œ ({len(session_list)}ê°œ íšŒì°¨)')

        for sess in session_list:
            questions = sessions[sess]
            print(f'   â€¢ {sess}íšŒ ({len(questions)}ë¬¸ì œ):')
            for q in questions[:2]:  # ê° íšŒì°¨ë‹¹ ìµœëŒ€ 2ë¬¸ì œë§Œ í‘œì‹œ
                title_short = q['title'][:70] + '...' if len(q['title']) > 70 else q['title']
                print(f'     - {q["full_id"]}: {title_short}')

    # 3. í†µê³„ ìš”ì•½
    print('\n\n' + '=' * 100)
    print('ğŸ“ˆ 3. ì¤‘ë³µ ì¶œì œ íŒ¨í„´ ìš”ì•½')
    print('=' * 100)

    print(f'\nâ€¢ ì™„ì „ ì¤‘ë³µ ë¬¸ì œ: {len(exact_duplicates)}ê°œ')
    print(f'â€¢ 2íšŒ ì´ìƒ ì¶œì œëœ í‚¤ì›Œë“œ: {len(frequent_keywords)}ê°œ')
    print(f'â€¢ ê³ ìœ  ì£¼ì œ (1íšŒë§Œ ì¶œì œ): ì•½ {len(all_questions) - len(exact_duplicates)}ê°œ')

    # ê°€ì¥ ìì£¼ ì¶œì œëœ í‚¤ì›Œë“œ TOP 10
    print('\n\nğŸ† ê°€ì¥ ìì£¼ ì¶œì œëœ ì£¼ì œ TOP 10:')
    print('-' * 100)

    top_10 = sorted_keywords[:10]
    for i, (kw, sessions) in enumerate(top_10, 1):
        total_count = sum(len(qs) for qs in sessions.values())
        session_nums = sorted(sessions.keys())
        print(f'{i:2d}. {kw:30s} - {total_count}íšŒ ì¶œì œ (íšŒì°¨: {", ".join(map(str, session_nums))})')

    # 4. ê²°ë¡  ë° í•™ìŠµ ì „ëµ
    print('\n\n' + '=' * 100)
    print('ğŸ’¡ 4. ê²°ë¡  ë° í•™ìŠµ ì „ëµ ì œì–¸')
    print('=' * 100)

    repetition_rate = (len(exact_duplicates) / len(all_questions)) * 100

    print(f'\nâ€¢ ì™„ì „ ì¤‘ë³µë¥ : {repetition_rate:.2f}%')

    if repetition_rate < 5:
        print('\nâœ… ê¶Œì¥ ì „ëµ: "ìµœì‹  íŠ¸ë Œë“œ ì¤‘ì‹¬ í•™ìŠµ"')
        print('   - ì™„ì „ ì¤‘ë³µ ë¬¸ì œê°€ ê±°ì˜ ì—†ìœ¼ë¯€ë¡œ, ê³¼ê±° ê¸°ì¶œì„ ê·¸ëŒ€ë¡œ ì•”ê¸°í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ')
        print('   - ëŒ€ì‹  í‚¤ì›Œë“œ ì¤‘ì‹¬ìœ¼ë¡œ ê°œë…ì„ ì´í•´í•˜ê³ , ìµœì‹  íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•œ í•™ìŠµ í•„ìš”')
        print('   - ì •ë¶€ ê°€ì´ë“œë¼ì¸, ìµœì‹  ê¸°ìˆ  ë™í–¥ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§')
    else:
        print('\nâš ï¸  ê¶Œì¥ ì „ëµ: "ê¸°ì¶œ ë¬¸ì œ ì¤‘ì‹¬ í•™ìŠµ"')
        print('   - ì¤‘ë³µ ì¶œì œìœ¨ì´ ë†’ìœ¼ë¯€ë¡œ ê³¼ê±° ê¸°ì¶œ ë¬¸ì œ ìˆ™ì§€ í•„ìš”')

    print(f'\nâ€¢ í‚¤ì›Œë“œ ë°˜ë³µ ì¶œì œìœ¨: ë†’ìŒ ({len(frequent_keywords)}ê°œ í‚¤ì›Œë“œ)')
    print('   â†’ í•µì‹¬ í‚¤ì›Œë“œ(LLM, ì œë¡œíŠ¸ëŸ¬ìŠ¤íŠ¸, DevOps ë“±)ëŠ” ë‹¤ì–‘í•œ ê°ë„ë¡œ ë°˜ë³µ ì¶œì œ')
    print('   â†’ í‚¤ì›Œë“œë³„ ë‹¤ì–‘í•œ ê´€ì (ê°œë…, êµ¬ì„±ìš”ì†Œ, ë³´ì•ˆ, í™œìš© ë“±)ì„ ì¤€ë¹„í•´ì•¼ í•¨')

if __name__ == '__main__':
    main()

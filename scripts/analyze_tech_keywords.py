#!/usr/bin/env python3
"""
129~137íšŒ ê¸°ìˆ  í‚¤ì›Œë“œ ì¤‘ë³µ ë¶„ì„ (ì¼ë°˜ ìš©ì–´ ì œì™¸)
"""

import json
import os
from collections import defaultdict
import re

# ì œì™¸í•  ì¼ë°˜ ìš©ì–´
EXCLUDE_TERMS = {
    'ì„¤ëª…í•˜ì‹œì˜¤', 'ëŒ€í•˜ì—¬', 'ë‹¤ìŒì„', 'ê´€ë ¨í•˜ì—¬', 'ì„¤ëª…í•˜ê³ ', 'ê°œë…ê³¼', 'í•„ìš”ì„±',
    'ë‹¨ê³„ë³„', 'í•­ëª©ì„', 'ê¸°ìˆ ì—', 'ë°©ì•ˆì„', 'ë‹¤ìŒì˜', 'ì„œë¹„ìŠ¤ë¥¼', 'ê¸°ë²•ì—',
    'ë‹¤ì–‘í•œ', 'ë¹„êµ', 'ê¸°ëŒ€íš¨ê³¼', 'íŠ¹ì§•ì„', 'ìœ í˜•ê³¼', 'ë°©ë²•ì„', 'ì‚¬ë¡€ë¥¼',
    'ì •ì˜ì™€', 'êµ¬ì„±ìš”ì†Œ', 'ìµœê·¼', 'í™œìš©', 'ë¶„ì„', 'ê°œë…ì„', 'ì›ë¦¬ë¥¼', 'ì ˆì°¨ë¥¼'
}

def is_tech_keyword(keyword):
    """ê¸°ìˆ  í‚¤ì›Œë“œì¸ì§€ íŒë‹¨ (ì¼ë°˜ ìš©ì–´ ì œì™¸)"""
    if keyword in EXCLUDE_TERMS:
        return False
    if len(keyword) < 3:  # ë„ˆë¬´ ì§§ì€ ê²ƒ ì œì™¸
        return False
    # ìˆœìˆ˜ ë™ì‚¬í˜• ì œì™¸
    if keyword.endswith('í•˜ì—¬') or keyword.endswith('í•˜ì‹œì˜¤'):
        return False
    return True

def extract_tech_keywords(title):
    """ì œëª©ì—ì„œ ê¸°ìˆ  í‚¤ì›Œë“œë§Œ ì¶”ì¶œ"""
    keywords = set()

    # 1. ì˜ë¬¸ ì•½ì–´ (ê´„í˜¸ ì•ˆ, ëŒ€ë¬¸ì ì‹œì‘)
    acronyms = re.findall(r'\(([A-Z][A-Za-z0-9\s,/&\-:\.]+)\)', title)
    for acronym in acronyms:
        # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²½ìš° ë¶„ë¦¬
        parts = [p.strip() for p in acronym.split(',')]
        keywords.update(parts)

    # 2. í•œê¸€ ê¸°ìˆ  ìš©ì–´ (íŠ¹ì • íŒ¨í„´)
    # í”„ë¡œí† ì½œ, ì•Œê³ ë¦¬ì¦˜, ì‹œìŠ¤í…œ, ëª¨ë¸, ê¸°ë²• ë“±
    tech_patterns = [
        r'[ê°€-í£]+(?:í”„ë¡œí† ì½œ|ì•Œê³ ë¦¬ì¦˜|ì‹œìŠ¤í…œ|ëª¨ë¸|ê¸°ë²•|ë°©ë²•ë¡ |ì•„í‚¤í…ì²˜|í”Œë«í¼|í”„ë ˆì„ì›Œí¬|ì—”ì§„|ë„êµ¬)',
        r'(?:ë”¥|ë¨¸ì‹ )ëŸ¬ë‹',
        r'[ê°€-í£]+(?:ì•”í˜¸|ë³´ì•ˆ|ì¸ì¦|ê²€ì¦)',
        r'[ê°€-í£]+(?:ë°ì´í„°ë² ì´ìŠ¤|ìŠ¤í† ë¦¬ì§€|ë©”ëª¨ë¦¬|ë„¤íŠ¸ì›Œí¬|ì„œë²„)',
        r'[ê°€-í£]+AI|AI[ê°€-í£]+',
        r'[ê°€-í£]+(?:í…ŒìŠ¤íŠ¸|ê°ë¦¬|í‰ê°€)',
        r'ì œë¡œ[ê°€-í£]+|[ê°€-í£]+ì œë¡œ',
        r'[ê°€-í£]{4,}(?:ë¶„ì„|ìµœì í™”|ê´€ë¦¬)',
    ]

    for pattern in tech_patterns:
        matches = re.findall(pattern, title)
        keywords.update(matches)

    # 3. ë³µí•© ê¸°ìˆ  ìš©ì–´ (ë„ì–´ì“°ê¸° í¬í•¨)
    compound_patterns = [
        r'(?:ì •ë³´|ë°ì´í„°|ì†Œí”„íŠ¸ì›¨ì–´|ì¸ê³µì§€ëŠ¥|ë¨¸ì‹ ëŸ¬ë‹)\s+[ê°€-í£]+',
        r'[ê°€-í£]+\s+(?:ì»´í“¨íŒ…|ë„¤íŠ¸ì›Œí‚¹|ë§ˆì´ë‹|ì—”ì§€ë‹ˆì–´ë§)',
    ]

    for pattern in compound_patterns:
        matches = re.findall(pattern, title)
        keywords.update(matches)

    # í•„í„°ë§
    filtered = {kw for kw in keywords if is_tech_keyword(kw)}

    return filtered

def main():
    # ëª¨ë“  íšŒì°¨ì˜ ë¬¸ì œ ìˆ˜ì§‘
    keyword_frequency = defaultdict(lambda: defaultdict(list))
    exam_sessions = range(129, 138)

    for session in exam_sessions:
        file_path = f'/Users/jyk/projects/sub-note/data/exam_results/{session}íšŒ_ë¶„ì„ê²°ê³¼.json'
        if not os.path.exists(file_path):
            continue

        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        questions_data = data.get('questions', {})
        for session_name, questions in questions_data.items():
            for q in questions:
                title = q.get('ì œëª©', '').strip()
                number = q.get('ë²ˆí˜¸', '')

                if not title:
                    continue

                full_id = f"{session}íšŒ {session_name} {number}"

                # ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ
                keywords = extract_tech_keywords(title)

                for kw in keywords:
                    keyword_frequency[kw][session].append({
                        'full_id': full_id,
                        'title': title
                    })

    print('=' * 100)
    print(f'ğŸ“Š 129~137íšŒ ê¸°ìˆ  í‚¤ì›Œë“œ ì¤‘ë³µ ë¶„ì„')
    print('=' * 100)

    # 2íšŒ ì´ìƒ ì¶œì œëœ ê¸°ìˆ  í‚¤ì›Œë“œë§Œ í•„í„°ë§
    frequent_keywords = {kw: sessions for kw, sessions in keyword_frequency.items()
                        if len(sessions) >= 2}

    # ì¶œì œ íšŸìˆ˜ ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_keywords = sorted(frequent_keywords.items(),
                            key=lambda x: sum(len(qs) for qs in x[1].values()),
                            reverse=True)

    print(f'\nì´ {len(sorted_keywords)}ê°œì˜ ê¸°ìˆ  í‚¤ì›Œë“œê°€ 2íšŒ ì´ìƒ ì¶œì œë¨\n')
    print('=' * 100)

    # TOP 50 ì¶œë ¥
    print(f'\nğŸ† ê°€ì¥ ìì£¼ ì¶œì œëœ ê¸°ìˆ  í‚¤ì›Œë“œ TOP 50:\n')
    print(f'{"ìˆœìœ„":^4} {"í‚¤ì›Œë“œ":^30} {"ì¶œì œ":^6} {"íšŒì°¨":<30}')
    print('-' * 100)

    for i, (kw, sessions) in enumerate(sorted_keywords[:50], 1):
        total_count = sum(len(qs) for qs in sessions.values())
        session_nums = sorted(sessions.keys())
        session_str = ', '.join(map(str, session_nums))

        print(f'{i:2d}.  {kw:25s}   {total_count:3d}íšŒ    {session_str}')

    # ìƒì„¸ ì¶œì œ ë‚´ìš© (TOP 20)
    print('\n\n' + '=' * 100)
    print('ğŸ“Œ TOP 20 í‚¤ì›Œë“œ ìƒì„¸ ì¶œì œ ë‚´ìš©')
    print('=' * 100)

    for i, (kw, sessions) in enumerate(sorted_keywords[:20], 1):
        total_count = sum(len(qs) for qs in sessions.values())
        session_list = sorted(sessions.keys())

        print(f'\n{i}. "{kw}" - ì´ {total_count}íšŒ ì¶œì œ ({len(session_list)}ê°œ íšŒì°¨)')
        print('-' * 100)

        for sess in session_list:
            questions = sessions[sess]
            print(f'\n   â€¢ {sess}íšŒ ({len(questions)}ë¬¸ì œ):')
            for q in questions:
                title_short = q['title'][:90] + '...' if len(q['title']) > 90 else q['title']
                print(f'     {q["full_id"]}: {title_short}')

    # í†µê³„ ìš”ì•½
    print('\n\n' + '=' * 100)
    print('ğŸ“ˆ í•™ìŠµ ìš°ì„ ìˆœìœ„ ì œì–¸')
    print('=' * 100)

    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
    ai_keywords = [kw for kw, _ in sorted_keywords if any(term in kw.lower() for term in ['ai', 'llm', 'model', 'learning', 'ë¨¸ì‹ ', 'ë”¥', 'ì¸ê³µì§€ëŠ¥', 'transformer', 'neural'])]
    security_keywords = [kw for kw, _ in sorted_keywords if any(term in kw.lower() for term in ['ë³´ì•ˆ', 'ì•”í˜¸', 'ì¸ì¦', 'security', 'zero', 'trust', 'ê³µê²©'])]
    data_keywords = [kw for kw, _ in sorted_keywords if any(term in kw.lower() for term in ['ë°ì´í„°', 'data', 'ë°ì´í„°ë² ì´ìŠ¤', 'database'])]
    sw_keywords = [kw for kw, _ in sorted_keywords if any(term in kw.lower() for term in ['ì†Œí”„íŠ¸ì›¨ì–´', 'software', 'dev', 'í…ŒìŠ¤íŠ¸', 'ê°ë¦¬', 'ê°œë°œ'])]

    print(f'\nğŸ¯ ì¹´í…Œê³ ë¦¬ë³„ ë°˜ë³µ ì¶œì œ í‚¤ì›Œë“œ:')
    print(f'\nâ€¢ AI/ML ê´€ë ¨: {len(ai_keywords)}ê°œ')
    print(f'  ì˜ˆì‹œ: {", ".join(ai_keywords[:5])}...')

    print(f'\nâ€¢ ì •ë³´ë³´ì•ˆ ê´€ë ¨: {len(security_keywords)}ê°œ')
    print(f'  ì˜ˆì‹œ: {", ".join(security_keywords[:5])}...')

    print(f'\nâ€¢ ë°ì´í„° ê´€ë ¨: {len(data_keywords)}ê°œ')
    print(f'  ì˜ˆì‹œ: {", ".join(data_keywords[:5])}...')

    print(f'\nâ€¢ ì†Œí”„íŠ¸ì›¨ì–´ ê´€ë ¨: {len(sw_keywords)}ê°œ')
    print(f'  ì˜ˆì‹œ: {", ".join(sw_keywords[:5])}...')

    print('\n\nğŸ’¡ ê²°ë¡ :')
    print('-' * 100)
    print('âœ… ì™„ì „ ì¤‘ë³µ ë¬¸ì œëŠ” 0ê°œ â†’ ê³¼ê±° ë¬¸ì œ ì•”ê¸° ë°©ì‹ì€ ë¬´ì˜ë¯¸')
    print('âœ… í•µì‹¬ í‚¤ì›Œë“œëŠ” ë‹¤ì–‘í•œ ê°ë„ë¡œ ë°˜ë³µ ì¶œì œ â†’ í‚¤ì›Œë“œ ì¤‘ì‹¬ ê°œë… í•™ìŠµ í•„ìˆ˜')
    print('âœ… ìµœì‹  íŠ¸ë Œë“œ (LLM, AI ê°€ì´ë“œë¼ì¸ ë“±)ê°€ ì§€ì† ì¶œì œ â†’ ì •ë¶€ ê³µì§€/ê°€ì´ë“œë¼ì¸ ëª¨ë‹ˆí„°ë§ í•„ìš”')
    print(f'âœ… {len(sorted_keywords)}ê°œ í‚¤ì›Œë“œê°€ 2íšŒ ì´ìƒ ì¶œì œ â†’ ì´ í‚¤ì›Œë“œë“¤ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•™ìŠµ ê³„íš ìˆ˜ë¦½')

if __name__ == '__main__':
    main()
